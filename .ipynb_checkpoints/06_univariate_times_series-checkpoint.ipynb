{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img src=\"./resources/GA.png\" width=\"25\" height=\"25\" />   <span style=\"color:Purple\">Project 5 :  Food Insecurity Regression Study</span> \n",
    "---\n",
    "## <span style=\"color:Green\"> 06 - Univariate Time Series Modeling</span>      \n",
    "\n",
    "#### Alec Edgecliffe-Johnson, Ryan McDonald, Andrew Roberts, Ira Seidman - General Assembly \n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we develop three univariate time series models using Arima, Auto Arima and Prophet to forecast predictions for food insecurity rates in a single state until 2026. We then develop a method to generate these predictions for each state in the country, save the predictions to a dataframe and then concatenate all dataframes together into a single dataframe. Ultimately, given the poor accuracy of the Arima and Auto-Arima models, we do not keep these models and instead use the predictions from the Prophet model as our forecasted Food Insecurity rates. We use this exported dataframe with our forecasts in Tableau, which is then hosted on our Streamlit app, the script for which can be found in the **'04_streamlit_code.py'** file in this repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Contents:\n",
    "\n",
    "- [Reading the Data](#intro)\n",
    "- [Model Preprocessing](#pre)\n",
    "- [Time Series Models](#model)\n",
    "    - [ARIMA](#ARIMA)\n",
    "    - [Auto-ARIMA](#auto)\n",
    "    - [Prophet](#prophet)\n",
    "    - [Aggregation 1 (ARIMA+Auto-ARIMA)](#agg1)\n",
    "    - [Aggregation 2 (ARIMA+Auto-ARIMA+Prophet)](#agg2)\n",
    "- [Merging Forecast w/ Original Data](#merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pmdarima'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c471c3343d4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpmdarima\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpmdarima\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfbprophet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProphet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pmdarima'"
     ]
    }
   ],
   "source": [
    "# Data manipulation imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modeling imports\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import datetime\n",
    "import pmdarima as pm\n",
    "from pmdarima.model_selection import train_test_split\n",
    "from fbprophet import Prophet\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## 1. Reading in the Datasets to clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/time_series/df_ts_state_mean_years.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping unnecessary columns, transposing and resetting index\n",
    "df = df.drop(columns = 'fips', axis = 1)\n",
    "df = df.rename(columns = {\"state_name\": \"\"})\n",
    "df_t = df.T\n",
    "df_t.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Exporting to CSV\n",
    "df_t.to_csv('./data/time_series/df_ts_rev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reimporting a renamed file\n",
    "df_rev = pd.read_csv('./data/time_series/df_ts_rev_fin_yr10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final drop\n",
    "df_rev = df_rev.drop(columns = 'Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev['time'] = pd.to_datetime(df_rev['time'], format = \"%Y/%m/%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pre'></a>\n",
    "## 2. Modeling Preprocessing - Make Train and Validation DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Credit to https://stackoverflow.com/questions/26921651/how-to-delete-the-last-row-of-data-of-a-pandas-dataframe\n",
    "df_train = pd.DataFrame(df_rev.drop(df_rev.tail(2).index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.DataFrame(df_rev.drop(df.head(7).index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model'></a>\n",
    "## 3. Models\n",
    "<a id='ARIMA'></a>\n",
    "### Model 1: ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Credit to https://www.youtube.com/watch?v=axjgEgBgIY0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "au = df_train[['time', 'Georgia']]\n",
    "au_v = df_val[['time', 'Georgia']]\n",
    "\n",
    "au.set_index('time', inplace = True)\n",
    "au_v.set_index('time', inplace = True)\n",
    "\n",
    "index_5_years = pd.date_range(au.index[-1], freq = 'AS-JAN', periods = 5, tz = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_arima = ARIMA(au, order = (1, 1, 1), freq = 'AS-JAN')\n",
    "model_arima_fit = mod_arima.fit()\n",
    "\n",
    "fcast1 = model_arima_fit.forecast(5)[0]\n",
    "\n",
    "fcast1 = pd.Series(fcast1, index = index_5_years)\n",
    "fcast1 = fcast1.rename('Arima');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15, 5))\n",
    "chart = sns.lineplot(x = 'time', y = 'Georgia', data = au)\n",
    "chart.set_title('AU')\n",
    "fcast1.plot(ax = ax, color = 'green', marker = 'o', legend = True)\n",
    "au.plot(ax = ax, color = 'blue', marker = 'o', legend = True)\n",
    "au_v.plot(ax = ax, color = 'orange', marker = 'o', legend = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='auto'></a>\n",
    "### Model 2: Auto-Arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Credit to https://www.youtube.com/watch?v=axjgEgBgIY0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima_mod = pm.auto_arima(au, seasonal = False, m = 0, error_action = 'ignore')\n",
    "fcast2 = auto_arima_mod.predict(5)\n",
    "fcast2 = pd.Series(fcast2, index = index_5_years)\n",
    "fcast2 = fcast2.rename('Auto_Arima')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15, 5))\n",
    "chart = sns.lineplot(x = 'time', y = 'Georgia', data = au)\n",
    "chart.set_title('AU')\n",
    "fcast2.plot(ax = ax, color = 'green', marker = 'o', legend = True)\n",
    "au.plot(ax = ax, color = 'blue', marker = 'o', legend = True)\n",
    "au_v.plot(ax = ax, color = 'orange', marker = 'o', legend = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prophet'></a>\n",
    "### Model 3: Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Credit to https://www.youtube.com/watch?v=axjgEgBgIY0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "au.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Copying and renaming \n",
    "au_c = df_train[['time', 'Georgia']].copy()\n",
    "au_c.columns = ['ds', 'y']\n",
    "au_c['ds'] = pd.to_datetime(au_c['ds'])\n",
    "\n",
    "model_p = Prophet(n_changepoints = 5, weekly_seasonality = False, daily_seasonality = False)\n",
    "model_p.fit(au_c)\n",
    "\n",
    "future = model_p.make_future_dataframe(5, freq = 'Y')\n",
    "\n",
    "#make predictions\n",
    "\n",
    "fcast3 = model_p.predict(future)\n",
    "\n",
    "fcast3 = pd.Series(fcast3['yhat'].values, name = 'Prophet', index = fcast3['ds']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15, 5))\n",
    "chart = sns.lineplot(x = 'time', y = 'Georgia', data = au)\n",
    "chart.set_title('AU')\n",
    "fcast3.plot(ax = ax, color = 'green', marker = 'o', legend = True)\n",
    "au.plot(ax = ax, color = 'blue', marker = 'o', legend = True)\n",
    "au_v.plot(ax = ax, color = 'orange', marker = 'o', legend = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'The MSE of Prophet is: {mean_squared_error(au_v['Georgia'].values, fcast3.values, squared= False)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='agg1'></a>\n",
    "### Model Aggregation 1: Running Arima and Auto-Arima Models Side-By-Side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Help and base code comes from: https://www.youtube.com/watch?v=axjgEgBgIY0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a states list for proof that it can work on multiple states.\n",
    "\n",
    "states = ['Georgia', 'Alabama']\n",
    "\n",
    "for s in states:\n",
    "    #training data\n",
    "    train_data = df_train[['time', s]]\n",
    "    \n",
    "    #valid data\n",
    "    valid_data = df_val[['time', s]]\n",
    "    \n",
    "    #all data\n",
    "    all_data = df_rev[['time', s]]\n",
    "    \n",
    "    #Set time column to index\n",
    "    train_data.set_index('time', inplace = True)\n",
    "    valid_data.set_index('time', inplace = True)\n",
    "    valid_data.columns = ['Valid Data'] ##To see it on the graph\n",
    "    all_data.set_index('time', inplace = True)\n",
    "    \n",
    "    #Set valid index for 5 years\n",
    "    index_7_years = pd.date_range(train_data.index[-1], freq = 'AS', periods = 7)\n",
    "    \n",
    "    #Future index - 5 years\n",
    "    future_7_years = pd.date_range(valid_data.index[-1], freq = 'AS', periods = 7)\n",
    "    \n",
    "    ## Tricky bit of code in order to basically reset the forecasts from the previous state. \n",
    "    # Otherwise, if a state fails to work in the Arima model, the forecast from the previous state is going to be passed in.\n",
    "    \n",
    "    #Drop all tables:\n",
    "    try:\n",
    "        del t_fcast1\n",
    "        del t_fcast2\n",
    "        #del t_fcast3\n",
    "    \n",
    "        del f_fcast1\n",
    "        del f_fcast2\n",
    "        #del f_fcast3\n",
    "    except:\n",
    "        print(\"\")\n",
    "    \n",
    "    try:\n",
    "        del t_fcast1\n",
    "        del t_fcast2\n",
    "        del t_fcast3\n",
    "    except:\n",
    "        print(\"\")\n",
    "\n",
    "## Arima Model ##\n",
    "\n",
    "#Arima Validation Phase \n",
    "\n",
    "    try:\n",
    "        model_arima = ARIMA(train_data, order=(1,1,1),freq='AS-JAN')\n",
    "        model_arima_fit = model_arima.fit()\n",
    "\n",
    "        t_fcast1 = model_arima_fit.forecast(7)[0]\n",
    "\n",
    "        t_fcast1 = pd.Series(fcast1, index=index_7_years)\n",
    "        t_fcast1 = t_fcast1.rename('Arima')\n",
    "    except:\n",
    "        print(s, 'Arima Train Error')\n",
    "          \n",
    "\n",
    "#Arima Future Phase\n",
    "            \n",
    "    try:\n",
    "        model_arima = ARIMA(all_data, order=(1,1,1),freq='AS-JAN')\n",
    "        model_arima_fit = model_arima.fit()\n",
    "\n",
    "        f_fcast1 = model_arima_fit.forecast(7)[0]\n",
    "\n",
    "        f_fcast1 = pd.Series(fcast1, index=future_7_years)\n",
    "        f_fcast1 = f_fcast1.rename('Future_Arima')\n",
    "    except:\n",
    "        print(s, 'Arima Future Error')\n",
    "        \n",
    "\n",
    "##### Auto-Arima #####\n",
    "\n",
    "\n",
    "#Auto Arima Valid phase\n",
    "    try:\n",
    "        auto_arima_model = pm.auto_arima(train_data, seasonal = False, m = 0,freq='AS-JAN', error_action='ignore')\n",
    "\n",
    "        t_fcast2 = auto_arima_model.predict(7)\n",
    "        t_fcast2 = pd.Series(t_fcast2, index=index_7_years)\n",
    "        t_fcast2 = t_fcast2.rename('Auto_Arima')\n",
    "    except:\n",
    "        print(s, 'Auto Arima Train Error')\n",
    "        \n",
    "\n",
    "#Auto Arima Future phase\n",
    "    try:\n",
    "        auto_arima_model = pm.auto_arima(all_data, seasonal = False, m = 0,freq='AS-JAN')\n",
    "\n",
    "        f_fcast2 = auto_arima_model.predict(7)\n",
    "        f_fcast2 = pd.Series(f_fcast2, index=future_7_years)\n",
    "        f_fcast2 = f_fcast2.rename('Future_Auto_Arima')\n",
    "    except:\n",
    "        print(s, 'Auto Arima Future Error')\n",
    "    \n",
    "#Plotting\n",
    "fig, ax = plt.subplots(figsize =(15,5))\n",
    "chart = sns.lineplot(x='time', y = s, data = train_data)\n",
    "chart.set_title(s)\n",
    "valid_data.plot(ax = ax, color = 'blue', marker = 'o', legend = True)\n",
    "#Plotting val\n",
    "try:\n",
    "    t_fcast1.plot(ax = ax, color = 'red', marker = 'o', legend = True)\n",
    "except:\n",
    "    print('')\n",
    "try:\n",
    "    t_fcast2.plot(ax = ax, color = 'green', marker = 'o', legend = True)\n",
    "except:\n",
    "    print('')\n",
    "    \n",
    "#plotting future\n",
    "try:\n",
    "     f_fcast1.plot(ax = ax, color = 'red', marker = 'v', legend = True)\n",
    "except:\n",
    "    print('')\n",
    "try:\n",
    "    f_fcast2.plot(ax = ax, color = 'green', marker = 'v', legend = True)\n",
    "except:\n",
    "    print('');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='agg2'></a>\n",
    "### Model Aggregation 2: Arima, Auto Arima and Prophet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **The below code aggregates all 4 ML Methods. Running with sereval ERRORS, but... running nonetheless!**\n",
    "**Will take a considerable (several minutes or more, based on your PC specs) time to run!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a full states list:\n",
    "\n",
    "states = [\"Alabama\",\"Alaska\",\"Arizona\",\"Arkansas\",\"California\",\"Colorado\",\n",
    "          \"Connecticut\",\"District of Columbia\", \"Delaware\",\"Florida\",\"Georgia\",\"Hawaii\",\"Idaho\",\n",
    "          \"Illinois\", \"Indiana\",\"Iowa\",\"Kansas\",\"Kentucky\",\"Louisiana\",\"Maine\",\"Maryland\",\n",
    "          \"Massachusetts\",\"Michigan\",\"Minnesota\",\"Mississippi\",\"Missouri\",\"Montana\",\n",
    "          \"Nebraska\",\"Nevada\",\"New Hampshire\",\"New Jersey\",\"New Mexico\",\"New York\",\n",
    "          \"North Carolina\",\"North Dakota\",\"Ohio\",\"Oklahoma\",\"Oregon\",\"Pennsylvania\",\n",
    "          \"Rhode Island\",\"South Carolina\",\"South Dakota\",\"Tennessee\",\"Texas\",\"Utah\",\n",
    "          \"Vermont\",\"Virginia\",\"Washington\",\"West Virginia\",\"Wisconsin\",\"Wyoming\"]\n",
    "\n",
    "for s in states:\n",
    "    #training data\n",
    "    train_data = df_train[['time', s]]\n",
    "    \n",
    "    #valid data\n",
    "    valid_data = df_val[['time', s]]\n",
    "    \n",
    "    #all data\n",
    "    all_data = df_rev[['time', s]]\n",
    "    \n",
    "    #Set time column to index\n",
    "    train_data.set_index('time', inplace=True)\n",
    "    valid_data.set_index('time', inplace=True)\n",
    "    valid_data.columns = ['Valid Data'] ##To see it on the graph\n",
    "    all_data.set_index('time', inplace=True)\n",
    "    \n",
    "    #Set valid index for 7 years\n",
    "    index_7_years = pd.date_range(train_data.index[-1], freq = 'AS', periods = 7)\n",
    "    \n",
    "    #Future index - 7 years\n",
    "    future_7_years = pd.date_range(valid_data.index[-1], freq = 'AS', periods = 7)\n",
    "    \n",
    "    ## Tricky bit of code in order to basically reset the forecasts from the previous state. \n",
    "    # Otherwise, if a state fails to work in the Arima model, the forecast from the previous state is going to be passed in.\n",
    "    \n",
    "    #Drop all tables:\n",
    "    try:\n",
    "        del t_fcast1\n",
    "        del t_fcast2\n",
    "        del t_fcast3\n",
    "#         del t_fcast4\n",
    "    \n",
    "        del f_fcast1\n",
    "        del f_fcast2\n",
    "        del f_fcast3\n",
    "#         del f_fcast4\n",
    "    except:\n",
    "        print(\"\")\n",
    "    \n",
    "    try:\n",
    "        del t_fcast1\n",
    "        del t_fcast2\n",
    "        del t_fcast3\n",
    "    except:\n",
    "        print(\"\")\n",
    "\n",
    "##################################################################################################################\n",
    "################################################ Arima #########################################################\n",
    "##################################################################################################################\n",
    "\n",
    "\n",
    "############################################# Arima Validation Phase ###################################################\n",
    "\n",
    "\n",
    "    try:\n",
    "        model_arima = ARIMA(train_data, order=(1, 1, 1),freq = 'AS-JAN');\n",
    "        model_arima_fit = model_arima.fit();\n",
    "\n",
    "        t_fcast1 = model_arima_fit.forecast(7)[0]\n",
    "\n",
    "        t_fcast1 = pd.Series(fcast1, index = index_7_years)\n",
    "        t_fcast1 = t_fcast1.rename('Arima')\n",
    "    except:\n",
    "        print(s, 'Arima Train Error')\n",
    "          \n",
    "\n",
    "################################################  Arima Future Phase ###################################################\n",
    "\n",
    "            \n",
    "    try:\n",
    "        model_arima = ARIMA(all_data, order = (1, 1, 1), freq = 'AS-JAN');\n",
    "        model_arima_fit = model_arima.fit();\n",
    "\n",
    "        f_fcast1 = model_arima_fit.forecast(7)[0]\n",
    "\n",
    "        f_fcast1 = pd.Series(fcast1, index = future_7_years)\n",
    "        f_fcast1 = f_fcast1.rename('Future_Arima')\n",
    "    except:\n",
    "        print(s, 'Arima Future Error')\n",
    "        \n",
    "\n",
    "##################################################################################################################\n",
    "################################################ Auto Arima ######################################################\n",
    "##################################################################################################################\n",
    "\n",
    "\n",
    "################################################  Auto Arima Validation Phase ###################################################\n",
    "\n",
    "    try:\n",
    "        auto_arima_model = pm.auto_arima(train_data, seasonal = False, m = 0)\n",
    "\n",
    "        t_fcast2 = auto_arima_model.predict(7)\n",
    "        t_fcast2 = pd.Series(t_fcast2, index = index_7_years)\n",
    "        t_fcast2 = t_fcast2.rename('Auto_Arima')\n",
    "    except:\n",
    "        print(s, 'Auto Arima Train Error')\n",
    "        \n",
    "\n",
    "################################################  Auto Arima Future Phase ###################################################\n",
    "   \n",
    "    try:\n",
    "        auto_arima_model = pm.auto_arima(all_data, seasonal = False, m = 0)\n",
    "\n",
    "        f_fcast2 = auto_arima_model.predict(7);\n",
    "        f_fcast2 = pd.Series(f_fcast2, index = future_7_years)\n",
    "        f_fcast2 = f_fcast2.rename('Future_Auto_Arima')\n",
    "    except:\n",
    "        print(s, 'Auto Arima Future Error')\n",
    "    \n",
    "##################################################################################################################\n",
    "################################################ Prophet #########################################################\n",
    "##################################################################################################################\n",
    "\n",
    "    #Expected column names Train\n",
    "    train_data3 = df_train[['time', s]].copy()\n",
    "    train_data3.columns = ['ds', 'y']\n",
    "    train_data3['ds'] = pd.to_datetime(train_data3['ds'])\n",
    "\n",
    "    #Expected column names Tall\n",
    "    all_data3 = df_rev[['time', s]].copy()\n",
    "    all_data3.columns = ['ds', 'y']\n",
    "    all_data3['ds'] = pd.to_datetime(all_data3['ds'])\n",
    "    \n",
    "################################################  Prophet Validation Phase ###################################################\n",
    "        \n",
    "    model_p = Prophet(daily_seasonality=False, weekly_seasonality=False);\n",
    "    model_p.fit(train_data3);\n",
    "\n",
    "    ##make validation index \n",
    "    val = model_p.make_future_dataframe(7, freq = 'Y')\n",
    "    \n",
    "    #make predictions\n",
    "    t_fcast3 = model_p.predict(val)\n",
    "    t_fcast3 = pd.Series(t_fcast3['yhat'].values, name = 'Prophet', index = t_fcast3['ds'])\n",
    "\n",
    "################################################  Prophet Future Phase #######################################################\n",
    "    \n",
    "    model_pf = Prophet(daily_seasonality=False, weekly_seasonality=False);\n",
    "    model_pf.fit(all_data3);\n",
    "\n",
    "    ##make validation index \n",
    "    future = model_pf.make_future_dataframe(7, freq = 'Y')\n",
    "    \n",
    "    #make predictions\n",
    "    f_fcast3 = model_pf.predict(future)\n",
    "    f_fcast3 = pd.Series(f_fcast3['yhat'].values, name = 'Future_Prophet', index = f_fcast3['ds'])\n",
    "\n",
    "\n",
    "                                                            \n",
    "##################################################################################################################\n",
    "################################################ Plotting ######################################################\n",
    "##################################################################################################################\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (15, 5))\n",
    "    chart = sns.lineplot(x = 'time', y = s, data = train_data)\n",
    "    chart.set_title(s)\n",
    "    valid_data.plot(ax = ax, color = 'blue', marker = 'o', legend = True);\n",
    "#Plotting val\n",
    "    try:\n",
    "        t_fcast1.plot(ax = ax, color = 'red', marker = 'o', legend = True);\n",
    "    except:\n",
    "        print('')\n",
    "    try:\n",
    "        t_fcast2.plot(ax = ax, color = 'green', marker = 'o', legend = True);\n",
    "    except:\n",
    "        print('')\n",
    "\n",
    "#plotting future\n",
    "    try:\n",
    "        f_fcast1.plot(ax = ax, color = 'red', marker = 'v', legend = True);\n",
    "    except:\n",
    "        print('')\n",
    "    try:\n",
    "        f_fcast2.plot(ax = ax, color = 'green', marker = 'v', legend = True);\n",
    "    except:\n",
    "        print('')\n",
    "    \n",
    "    t_fcast3.plot(ax = ax, color = 'orange', marker = 'o', legend = True);\n",
    "    f_fcast3.plot(ax = ax, color = 'orange', marker = 'o', legend = True);\n",
    "#     t_fcast4.plot(ax = ax, color = 'black', marker = 'o', legend = True)\n",
    "#     f_fcast4.plot(ax = ax, color = 'black', marker = 'o', legend = True)\n",
    "\n",
    "##################################################################################################################\n",
    "################################################ Saving into DataFrames ##########################################\n",
    "##################################################################################################################\n",
    "\n",
    "################################################  DF Arima #######################################################\n",
    "\n",
    "    try:\n",
    "        #Creating df for forecast1\n",
    "        t_fcast1 = t_fcast1.reset_index()\n",
    "        t_fcast1.columns = ['Year', 'Arima ForecastValue Validation']\n",
    "        \n",
    "        f_fcast1 = f_fcast1.reset_index()\n",
    "        f_fcast1.columns = ['Year', 'Arima ForecastValue Future']\n",
    "        \n",
    "        #Extra Columns\n",
    "        t_fcast1['Arima ForecastValue Future'] = np.nan\n",
    "        f_fcast1['Arima ForecastValue Validation'] = np.nan\n",
    "        \n",
    "        #Reordering\n",
    "        t_fcast1 = t_fcast1[['Year', 'Arima ForecastValue Future', 'Arima ForecastValue Validation']]\n",
    "        \n",
    "        # Joining them togther\n",
    "        df_fcast1 = pd.concat([t_fcast1, f_fcast1], axis = 0)\n",
    "        df_fcast1['State'] = s\n",
    "        df_fcast1['ML Method'] = 'Arima'\n",
    "#         df_fcast1['Arima MSE'] = t_fcast1_mse\n",
    "    \n",
    "    except:\n",
    "        df_fcast1 = pd.DataFrame({'Year': [np.nan], 'Arima ForecastValue Future': [np.nan], 'Arima ForecastValue Validation': [np.nan], 'State': [s], 'ML Method': ['Arima']})\n",
    "\n",
    "################################################  DF Auto Arima #######################################################\n",
    "     \n",
    "    try:\n",
    "        #Creating df for forecast2\n",
    "        t_fcast2 = t_fcast2.reset_index()\n",
    "        t_fcast2.columns = ['Year', 'Auto Arima ForecastValue Validation']\n",
    "        \n",
    "        f_fcast2 = f_fcast2.reset_index()\n",
    "        f_fcast2.columns = ['Year', 'Auto Arima ForecastValue Future']\n",
    "        \n",
    "        #Extra Columns\n",
    "        t_fcast2['Auto Arima ForecastValue Future'] = np.nan\n",
    "        f_fcast2['Auto Arima ForecastValue Validation'] = np.nan\n",
    "        \n",
    "        #Reordering\n",
    "        t_fcast2 = t_fcast2[['Year', 'Auto Arima ForecastValue Future', 'Auto Arima ForecastValue Validation']]\n",
    "        \n",
    "        # Joining them togther\n",
    "        df_fcast2 = pd.concat([t_fcast2, f_fcast2], axis = 0)\n",
    "        df_fcast2['State'] = s\n",
    "        df_fcast2['ML Method'] = 'Auto Arima'\n",
    "#         df_fcast2['Auto Arima MSE'] = t_fcast2_mse\n",
    "    \n",
    "    except:\n",
    "        df_fcast2 = pd.DataFrame({'Year': [np.nan], 'Auto Arima ForecastValue Future': [np.nan], 'Auto Arima ForecastValue Validation': [np.nan], 'State': [s], 'ML Method': ['Auto Arima']})\n",
    "\n",
    "################################################  DF Prophet #######################################################\n",
    "     \n",
    "    try:\n",
    "        #Creating df for forecast3\n",
    "        t_fcast3 = t_fcast3.reset_index()\n",
    "        t_fcast3.columns = ['Year', 'Prophet ForecastValue Validation']\n",
    "    \n",
    "        f_fcast3 = f_fcast3.reset_index()\n",
    "        f_fcast3.columns = ['Year', 'Prophet ForecastValue Future']\n",
    "        \n",
    "        #Extra Columns\n",
    "        t_fcast3['Prophet ForecastValue Future'] = np.nan\n",
    "        f_fcast3['Prophet ForecastValue Validation'] = np.nan\n",
    "        \n",
    "        #Reordering\n",
    "        t_fcast3 = t_fcast3[['Year', 'Prophet ForecastValue Future', 'Prophet ForecastValue Validation']]\n",
    "        \n",
    "        # Joining them togther\n",
    "        df_fcast3 = pd.concat([t_fcast3, f_fcast3], axis = 0)\n",
    "        df_fcast3['State'] = s\n",
    "        df_fcast3['ML Method'] = 'Prophet'\n",
    "#         df_fcast3['Prophet MSE'] = t_fcast3_mse\n",
    "\n",
    "    except:\n",
    "        df_fcast2 = pd.DataFrame({'Year': [np.nan], 'Prophet ForecastValue Future': [np.nan], 'Prophet ForecastValue Validation': [np.nan], 'State': [s], 'ML Method': ['Prophet']})\n",
    "        \n",
    "################################################ Aggregating and Joining #######################################################\n",
    "\n",
    "#     df_fcast1 = df_fcast1.groupby(['Year', 'State', 'ML Method'], as_index = False).agg({'Arima ForecastValue Future': 'sum', 'Arima ForecastValue Validation': 'sum'})\n",
    "#     df_fcast2 = df_fcast2.groupby(['Year', 'State', 'ML Method'], as_index = False).agg({'Auto Arima ForecastValue Future': 'sum', 'Auto Arima ForecastValue Validation': 'sum'})\n",
    "    df_fcast3 = df_fcast3.groupby(['Year', 'State', 'ML Method'], as_index = False).agg({'Prophet ForecastValue Future': 'sum', 'Prophet ForecastValue Validation': 'sum'})\n",
    "        \n",
    "    all_forecasts = df_fcast3.copy()\n",
    "#     all_forecasts = df_fcast3.merge(df_fcast2[['Year', 'Auto Arima ForecastValue Future', 'Auto Arima ForecastValue Validation']], how ='left', on = 'Year').copy()\n",
    "#     all_forecasts = pd.DataFrame(all_forecasts.merge(df_fcast1[['Year', 'Arima ForecastValue Future', 'Arima ForecastValue Validation']], how ='left', on = 'Year'))\n",
    "        \n",
    "        #Save predictions in df. First time this will fail and just give all_forecasts, after that will concat for each state\n",
    "    try: \n",
    "        final_forecasts = pd.concat([final_forecasts, all_forecasts], ignore_index = True)\n",
    "    except:\n",
    "        final_forecasts = all_forecasts;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_forecasts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_forecasts.to_csv('./data/time_series/final_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='merge'></a>\n",
    "## 4. Merging Final Forecasts with Original Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Formatting completed in the initial run.  Below is commented out for data preservation**\n",
    "\n",
    "Merging the final forecasts with original data. However our original dataframe is in the wrong format, so we import a new one that has a \"states\" row with the historical data in the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in our original data in the correct format and final_forecasts (which we exported above)\n",
    "df_data = pd.read_csv('./data/time_series/hor_states.csv')\n",
    "\n",
    "final_forecasts = pd.read_csv('./data/time_series/final_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting already applied. Commented out to preserve data\n",
    "\n",
    "# Setting consistent columns\n",
    "df_data['Prophet ForecastValue Future'] = np.nan\n",
    "df_data['Prophet ForecastValue Validation'] = np.nan\n",
    "\n",
    "# df_data['Year'] = pd.to_datetime(df_data['Year'])\n",
    "#Dropping Ml Method as it is not necessary\n",
    "del final_forecasts['ML Method']\n",
    "\n",
    "#adding this column to keep consistency across both before union\n",
    "final_forecasts['fi'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting already applied. Commented out to preserve data\n",
    "#Converting both to datetime so types are the same for the concat\n",
    "df_data['Year'] = pd.to_datetime(df_data['Year'])\n",
    "final_forecasts['Year'] = pd.to_datetime(final_forecasts['Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_forecasts.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting already applied. Commented out to preserve data\n",
    "# Reordering for concat\n",
    "\n",
    "final_forecasts = final_forecasts[['Unnamed: 0', 'Year', 'State', 'fi', 'Prophet ForecastValue Future', 'Prophet ForecastValue Validation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting already applied. Commented out to preserve data\n",
    "# Concatening and dropping and renaming columns \n",
    "output_df = pd.concat([df_data, final_forecasts], axis = 0)\n",
    "\n",
    "del output_df['Unnamed: 0']\n",
    "\n",
    "output_df.rename(columns = {'fi': 'Food Insecurity Rate'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting to CSV\n",
    "output_df.to_csv('./data/time_series/output_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
